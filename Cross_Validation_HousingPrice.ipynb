{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNgFgO1JCmXtLMnAtU2NHtw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ReyhaneTaj/Data-Science-Practices/blob/main/Cross_Validation_HousingPrice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20DaBklfU8jC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cross-Validation: Description and Example in Housing Price Prediction\n",
        "\n",
        "#### **What is Cross-Validation?**\n",
        "\n",
        "Cross-validation is a robust technique used to assess the generalization ability of a machine learning model. Instead of relying on a single train-test split, cross-validation repeatedly splits the data into training and validation sets in different ways. This approach helps to ensure that the model's performance is not dependent on a particular split of the data, providing a more reliable estimate of how well the model will perform on unseen data.\n",
        "\n",
        "#### **When to Use Cross-Validation**\n",
        "\n",
        "Cross-validation is particularly useful in the following scenarios:\n",
        "\n",
        "- **Limited Data**: When the dataset is small, cross-validation helps make the most out of the available data by using each observation for both training and validation.\n",
        "- **Model Evaluation**: When you need a reliable estimate of model performance and want to avoid overfitting to a specific train-test split.\n",
        "- **Model Comparison**: When comparing different models or hyperparameter settings, cross-validation provides a more accurate measure of their performance.\n",
        "- **Preventing Data Leakage**: By validating on different subsets of data, cross-validation helps in identifying potential data leakage issues and ensuring that the model generalizes well.\n",
        "\n",
        "#### **Why is Cross-Validation Important?**\n",
        "\n",
        "- **Reduces Overfitting**: By using multiple splits of the data, cross-validation helps in reducing overfitting, ensuring that the model generalizes well to new data.\n",
        "- **More Reliable Performance Metrics**: Since performance is averaged over multiple splits, the metrics like accuracy, MAE, or RÂ² are more reliable and less biased.\n",
        "- **Better Model Selection**: Cross-validation provides a clearer picture of how different models or hyperparameters perform, aiding in the selection of the best model for the task.\n",
        "\n",
        "#### **Example: Cross-Validation in Housing Price Prediction**\n",
        "\n",
        "Let's consider an example using the popular housing price dataset. We will use `KFold` cross-validation to evaluate a simple linear regression model.\n"
      ],
      "metadata": {
        "id": "ODj4NiDzU9k5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "# Load the California housing dataset\n",
        "housing = fetch_california_housing()\n",
        "X, y = housing.data, housing.target\n",
        "\n",
        "# Initialize the model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Setup KFold cross-validation with 5 splits\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Perform cross-validation and calculate the mean squared error for each fold\n",
        "mse_scores = -cross_val_score(model, X, y, cv=kf, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Calculate and print the mean and standard deviation of the MSE scores\n",
        "print(f\"Mean MSE: {np.mean(mse_scores):.4f}\")\n",
        "print(f\"Standard Deviation of MSE: {np.std(mse_scores):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzNfnNEDVeGK",
        "outputId": "0499077d-b7e5-430b-d334-4162cef9e374"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean MSE: 0.5306\n",
            "Standard Deviation of MSE: 0.0218\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Explanation of the Example:**\n",
        "\n",
        "- **KFold Cross-Validation**: The dataset is split into 5 parts (folds). The model is trained on 4 folds and validated on the remaining fold. This process is repeated 5 times, with each fold serving as the validation set once.\n",
        "\n",
        "- **Model Performance**: The mean squared error (MSE) is computed for each fold, and the average MSE provides an estimate of the model's performance. The standard deviation indicates the variability of the model's performance across different data splits.\n",
        "\n",
        "- **Interpretation**: A mean MSE of 0.5306 and a standard deviation of 0.0218 suggest that the model performs consistently well across different data subsets. The relatively low standard deviation indicates stable performance across the folds, making this model a reliable choice for predicting housing prices.\n",
        "\n",
        "This example demonstrates how cross-validation can be used to evaluate the performance of a model in a more robust and reliable manner.\n"
      ],
      "metadata": {
        "id": "DyWOoj6JWEES"
      }
    }
  ]
